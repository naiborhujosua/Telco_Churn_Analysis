# Implementing the Customer Churn Analysis in Telco Industry to improving Customer retention using Pyspark in Databricks
This project is a part of my journey learning pyspark and how databricks can be useful for Deploying Machine Learning Algorithms in the Cloud. I use [IBM dataset](https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113) for exploring the dataset, doing exploratory analysis and implement Machine learning algorithms to derive actionable insights.

#### -- Project Status: [Active]
<img src="https://static1.squarespace.com/static/5144a1bde4b033f38036b7b9/t/56ab72ebbe7b96fafe9303f5/1454076676264/"/>
## Project Intro/Objective
Customers are one of the most important factors in the growth of the company. The knowledge of customer's needs is essential to make a profitable and sustainable company. Hence, The process to analyze customer needs retention plays a significant part in improving the company's growth, protects loyal customers, and improve its customer relationship management (CRM). We will build an end-to-end Machine Learning Project to analyze the telco industry based on the fictional dataset provided by IBM by using pyspark in the free community edition of Databricks. This Telco churn dataset contains a fictional telco company that provided home phone and internet services to 7034 customers in California. The dataset consists include information about the customers who left, stayed, and sign up within the last month, demographic info about the customers' age range, gender, and customer account information that we will see in the databricks.


### Partner
* [Name of Partner organization/Government department etc..]
* Website for partner
* Partner contact: [Name of Contact], [slack handle of contact if any]
* If you do not have a partner leave this section out

### Methods Used
* Descriptive Statistics
* Inferential Statistics
* Machine Learning
* Data Visualization
* Predictive Modeling

### Technologies
* Python
* PostGres
* Pandas, jupyter
* HTML
* Pyspark


## Project Description
(Provide more detailed overview of the project.  Talk a bit about your data sources and what questions and hypothesis you are exploring. What specific data analysis/visualization and modelling work are you using to solve the problem? What blockers and challenges are you facing?  Feel free to number or bullet point things here)



## Getting Started

1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data is being kept [here](Repo folder containing raw data) within this repo.

    *If using offline data mention that and how they may obtain the data from the froup)*
    
3. Data processing/transformation scripts are being kept [here](Repo folder containing data processing scripts/notebooks)
4. etc...

*If your project is well underway and setup is fairly complicated (ie. requires installation of many packages) create another "setup.md" file and link to it here*  


